{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "AI4M_C3_M1_lecture_nb_sklearn.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhle/AI_for_Medicine_Specification/blob/master/AI_treatment/week1/AI4M_C3_M1_lecture_nb_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM5ycXQnuET9",
        "colab_type": "text"
      },
      "source": [
        "## AI for Medicine Course 3 Week 1 lecture notebook - Model Training/Tuning Basics with Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSg27ftkuET-",
        "colab_type": "text"
      },
      "source": [
        "Welcome to this exercise! You're going to be exploring the `sklearn` library, including an overview of its underlying data types and methods for tweaking a model's hyperparameters. You'll be using the same data from the previous lecture notebook. Let's get started!"
      ]
    },
    
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu2M2tyUuET_",
        "colab_type": "text"
      },
      "source": [
        "### Packages\n",
        "\n",
        "First import all the packages that you need for this assignment. \n",
        "\n",
        "\n",
        "- `pandas` is what you'll use to manipulate your data\n",
        "- `numpy`  is a library for mathematical and scientific operations\n",
        "- `sklearn` has many efficient tools for machine learning and statistical modeling\n",
        "- `itertools` helps with hyperparameter (grid) searching\n",
        "\n",
        "### Import Packages\n",
        "\n",
        "Run the next cell to import all the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl5hgAzduET_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Set the random seed for consistent output\n",
        "np.random.seed(18)\n",
        "\n",
        "# Read in the data\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/anhle/AI_for_Medicine_Specification/master/AI_treatment/week1/dummy_data.csv\", index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iav7jyUVuEUD",
        "colab_type": "text"
      },
      "source": [
        "### Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pDEYBhfuEUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import module to split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Get the label\n",
        "y = data.outcome\n",
        "\n",
        "# Get the features\n",
        "X = data.drop('outcome', axis=1) \n",
        "\n",
        "# Get training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
        "print(f\"Number of observations for training: {y_train.size}\")\n",
        "print(f\"Number of observations for testing: {y_test.size}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQAqyIuIuEUH",
        "colab_type": "text"
      },
      "source": [
        "### Model Fit and Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpcOSA1-uEUH",
        "colab_type": "text"
      },
      "source": [
        "Let's fit a logistic regression to the training data. `Sklearn` allows you to provide arguments that override the defaults. \n",
        "\n",
        "The default solver is `lbfgs`.  \n",
        "- Lbfgs stands for ['Limited Memory BFGS'](https://en.wikipedia.org/wiki/Limited-memory_BFGS), and is an efficient and popular method for fitting models.\n",
        "- The solver is set explicitly here for learning purposes; if you do not set the solver parameter explicitly, the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) function will use its default solver, which is lbfgs as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx4ZPlHwuEUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(solver='lbfgs')\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw-1kkiTuEUK",
        "colab_type": "text"
      },
      "source": [
        "When it fits the training data, `sklearn` also prints out the model's hyperparameters.  \n",
        "- Here, these are the default hyperparameters for `sklearn's` logistic regression classifier.\n",
        "- Another way to check these parameters is the `get_params()` method of the classifier.\n",
        "\n",
        "You should spend some time checking out the [documentation](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) to get a deeper understanding of what's going on. One important thing to note is that each classifier has different hyperparameters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XouWMhzIuEUL",
        "colab_type": "text"
      },
      "source": [
        "### Prediction\n",
        "To predict with the classifier, use the `predict()` method. \n",
        "- This returns a `numpy` array containing the predicted class for each observation in the test set, as you can see by running the next cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "405nPANduEUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the trained model to predict labels from the features of the test set\n",
        "predictions = lr.predict(X_test)\n",
        "\n",
        "# View the prediction type, shape, and print out a sample prediction\n",
        "print(f\"predictions is of type: {type(predictions)}\")\n",
        "print(f\"predictions has shape: {predictions.shape}\")\n",
        "print(f\"predicted class for 10th element in test set: {predictions[9]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCLejPi7uEUP",
        "colab_type": "text"
      },
      "source": [
        "### Prediction probability\n",
        "\n",
        "When a model predicts that a label is 1 rather than 0, it may help you to know if the model was predicting 1 with a 51% probability or 90% probability; in other words, how confident is that prediction?\n",
        "\n",
        "You can get the model's probability of predicting each of the class. \n",
        "- To do this, use the `predict_proba()` method. \n",
        "- The resulting array will have a shape that matches the number of classes for the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9Ak0JKAuEUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_probs = lr.predict_proba(X_test)\n",
        "print(f\"prediction_probs is of type: {type(prediction_probs)}\")\n",
        "print(f\"prediction_probs has shape: {prediction_probs.shape}\")\n",
        "print(f\"probabilities for first element in test set: {prediction_probs[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCqUdoLDuEUS",
        "colab_type": "text"
      },
      "source": [
        "There are 13 patients in the test set.  Each patient's label could be either 0 or 1, so the prediction probability has 13 rows and 2 columns.  To know which column refers to lable 0 and which refers to label 1, you can check the `.classes_` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_CBitCJuEUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr.classes_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKpYz7atuEUV",
        "colab_type": "text"
      },
      "source": [
        "Since the order of the `classes_` array is 0, then 1, column 0 of the prediction probabilities has label 0, and column 1 has label 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3_buN75uEUW",
        "colab_type": "text"
      },
      "source": [
        "Let's print these for the first 5 elements of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgQ4T6IwuEUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5):\n",
        "    print(f\"Element number: {i}\")\n",
        "    print(f\"Predicted class: {predictions[i]}\")\n",
        "    print(f\"Probability of predicting class 0: {prediction_probs[i][0]}\")\n",
        "    print(f\"Probability of predicting class 1: {prediction_probs[i][1]}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUln3nUZuEUZ",
        "colab_type": "text"
      },
      "source": [
        "You can see here that the predicted class matches the class with a higher probability of being predicted. Since you're dealing with `numpy` arrays, you can simply slice them and get specific information, such as the probability of predicting class 1 for all elements in the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxfVaz9uuEUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrieve prediction probabilities for label 1, for all patients\n",
        "prediction_probs[:, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stE1Cj89uEUb",
        "colab_type": "text"
      },
      "source": [
        "### Tuning the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ota9HubpuEUc",
        "colab_type": "text"
      },
      "source": [
        "Most of the time, the predictive power of a classifier can be increased if a good set of hyperparameters is defined. This is known as model tuning. \n",
        "\n",
        "For this process, you'll need a classifier, an appropriate evaluation metric, and a set of parameters to test. Since this is a dummy example, you'll use the default metric for the logistic regression classifier: the **mean accuracy**.\n",
        "\n",
        "### Mean Accuracy\n",
        "Mean Accuracy is the number of correct predictions divided by total predictions. This can be computed with the `score()` method. \n",
        "\n",
        "Let's begin by checking the performance of your out-of-the-box logit classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w93zvMBeuEUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir2fcgl9uEUf",
        "colab_type": "text"
      },
      "source": [
        "Let's say you want to tweak this model's default parameters. You can pass a dictionary containing the values you specify to the classifier when you instantiate it. Notice that these must be passed as keyword arguments, or `kwargs`, which are created by using the ** prefix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3mLAe3vGuEUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose hyperparameters and place them as key-value pairs in a dictionary\n",
        "params = {\n",
        "    'solver': 'liblinear',\n",
        "    'fit_intercept': False,\n",
        "    'penalty': 'l1',\n",
        "    'max_iter': 500\n",
        "}\n",
        "\n",
        "# Pass in the dictionary as keyword arguments to the model\n",
        "lr_tweaked = LogisticRegression(**params)\n",
        "\n",
        "# Train the model\n",
        "lr_tweaked.fit(X_train, y_train)\n",
        "\n",
        "# View hyper-parameters\n",
        "print(f\"Tweaked hyperparameters: {lr_tweaked.get_params()}\\n\")\n",
        "\n",
        "# Evaluate the model with the mean accuracy\n",
        "print(f\"Mean Accuracy: {lr_tweaked.score(X_test, y_test)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Glg2x-uEUh",
        "colab_type": "text"
      },
      "source": [
        "The model with the tweaked parameters is worse than the original! However, there might still be some combination of parameters that increase the predictive power of your logit classifier. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPBs5IYluEUi",
        "colab_type": "text"
      },
      "source": [
        "### Try different hyperparameters\n",
        "Testing this can be daunting considering all the possible parameter combinations. Let's try something \n",
        "\n",
        "To get started, you'll apply `itertools.product()` to create all the combinations of parameters. \n",
        "- Notice that the iterable (in this case a list of the lists of parameters) must be passed as *args to the `product()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b9QHaUfuEUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choose hyperparameters and place in a dictionary\n",
        "hyperparams = {\n",
        "    'solver': [\"liblinear\"],\n",
        "    'fit_intercept': [True, False],\n",
        "    'penalty': [\"l1\", \"l2\"],\n",
        "    'class_weight': [None, \"balanced\"]\n",
        "}\n",
        "# Get the values of hyperparams and convert them to a list of lists\n",
        "hp_values = list(hyperparams.values())\n",
        "hp_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUQ7nXDVuEUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get every combination of the hyperparameters\n",
        "for hp in itertools.product(*hp_values):\n",
        "    print(hp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npvnya0duEUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loop through the combinations of hyperparams\n",
        "for hp in itertools.product(*hp_values):\n",
        "\n",
        "    # Create the model with the hyperparams\n",
        "    estimator = LogisticRegression(solver=hp[0],\n",
        "                                   fit_intercept=hp[1],\n",
        "                                   penalty=hp[2],\n",
        "                                   class_weight=hp[3])\n",
        "    # Fit the model\n",
        "    estimator.fit(X_train, y_train)\n",
        "    print(f\"Parameters used: {hp}\")\n",
        "    print(f\"Mean accuracy of the model: {estimator.score(X_test, y_test)}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8IZ1WuHuEUq",
        "colab_type": "text"
      },
      "source": [
        "Note that in the graded assignment, you will take a more generalizable approach that doesn't require you to explicitly specify each hyperparameter.\n",
        "\n",
        "That is, instead of:\n",
        "\n",
        "```CPP\n",
        "LogisticRegression(solver=hp[0],fit_intercept=hp[1],...\n",
        "```\n",
        "\n",
        "You'll be able to write:\n",
        "```CPP\n",
        "LogisticRegression(**params)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-c_9lkeuEUq",
        "colab_type": "text"
      },
      "source": [
        "Looks like none of these models beats the original! This won't always be the case, so next time the opportunity arises, you'll be able to check this for yourself. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTpWV6ZquEUr",
        "colab_type": "text"
      },
      "source": [
        "### Grid Search\n",
        "\n",
        "This is essentially grid search.  You'll be implementing customized grid search in the graded assignment.  \n",
        "- Note that even though sci-kit learn provides a grid search function, it uses K-fold cross validation, which you won't want to do in the assignment, which is why you will implement grid search yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YblCdVL9uEUs",
        "colab_type": "text"
      },
      "source": [
        "### Congratulations on completing this lecture notebook! \n",
        "\n",
        "By now, you should feel more comfortable with the `sklearn` library and how it works. You also created a grid search from scratch by leveraging the `itertools` library. Nice work!"
      ]
    }
  ]
}
