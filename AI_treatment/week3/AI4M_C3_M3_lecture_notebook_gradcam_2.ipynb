{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "AI4M_C3_M3_lecture_notebook_gradcam_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhle/AI_for_Medicine_Specification/blob/master/AI_treatment/week3/AI4M_C3_M3_lecture_notebook_gradcam_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HjRrq4B8RLc",
        "colab_type": "text"
      },
      "source": [
        "# GradCAM: Continuation (Part 2) - Lecture Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-ze6wqn8RLe",
        "colab_type": "text"
      },
      "source": [
        "In the previous lecture notebook (GradCAM Part 1) we explored what Grad-Cam is and why it is useful. We also looked at how we can compute the activations of a particular layer using Keras API. In this notebook we will check the other element that Grad-CAM requires, the gradients of the model's output with respect to our desired layer's output. This is the \"Grad\" portion of Grad-CAM. \n",
        "\n",
        "Let's dive into it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA3Zgizb8kyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWxITent8xbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzip data to '/content' folder\n",
        "!unzip '/content/drive/My Drive/data/AI_for_Medicine_Specification/AI_diagnosis/w1/small_data.zip'\n",
        "!cp '/content/drive/My Drive/data/AI_for_Medicine_Specification/AI_diagnosis/w1/valid-small.csv' /content/\n",
        "!cp '/content/drive/My Drive/data/AI_for_Medicine_Specification/AI_diagnosis/w1/train-small.csv' /content/\n",
        "!cp '/content/drive/My Drive/data/AI_for_Medicine_Specification/AI_diagnosis/w1/test.csv' /content/\n",
        "!cp '/content/drive/My Drive/data/AI_for_Medicine_Specification/AI_diagnosis/w1/densenet.hdf5' /content/\n",
        "!cp '/content/drive/My Drive/data/AI_for_Medicine_Specification/AI_diagnosis/w1/pretrained_model.h5' /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NUh24N08RLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install lifelines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2VkQiKl9EPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#UTILS FILE\n",
        "import keras\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# For part 2\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import lifelines\n",
        "\n",
        "IMAGE_DIR = \"small_data/\"\n",
        "\n",
        "def get_mean_std_per_batch(df, H=320, W=320):\n",
        "    sample_data = []\n",
        "    for idx, img in enumerate(df.sample(100)[\"Image\"].values):\n",
        "        path = IMAGE_DIR + img\n",
        "        sample_data.append(np.array(image.load_img(path, target_size=(H, W))))\n",
        "\n",
        "    mean = np.mean(sample_data[0])\n",
        "    std = np.std(sample_data[0])\n",
        "    return mean, std    \n",
        "\n",
        "def load_image_normalize(path, mean, std, H=320, W=320):\n",
        "    x = image.load_img(path, target_size=(H, W))\n",
        "    x -= mean\n",
        "    x /= std\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "def load_image(path, df, preprocess=True, H = 320, W = 320):\n",
        "    \"\"\"Load and preprocess image.\"\"\"\n",
        "    x = image.load_img(path, target_size=(H, W))\n",
        "    if preprocess:\n",
        "        mean, std = get_mean_std_per_batch(df, H=H, W=W)\n",
        "        x -= mean\n",
        "        x /= std\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "    return x\n",
        "\n",
        "def compute_gradcam(model, img, data_dir, df, labels, selected_labels, layer_name='bn'):\n",
        "    img_path = data_dir + img\n",
        "    preprocessed_input = load_image(img_path, df)\n",
        "    predictions = model.predict(preprocessed_input)\n",
        "    print(\"Ground Truth: \", \", \".join(np.take(labels, np.nonzero(df[df[\"Image\"] == img][labels].values[0]))[0]))\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.subplot(151)\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis('off')\n",
        "    plt.imshow(load_image(img_path, df, preprocess=False), cmap='gray')\n",
        "    \n",
        "    j = 1\n",
        "    for i in range(len(labels)):\n",
        "        if labels[i] in selected_labels:\n",
        "            print(\"Generating gradcam for class %s (p=%2.2f)\" % (labels[i], round(predictions[0][i], 3)))\n",
        "            gradcam = grad_cam(model, preprocessed_input, i, layer_name)\n",
        "            plt.subplot(151 + j)\n",
        "            plt.title(labels[i] + \": \" + str(round(predictions[0][i], 3)))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(load_image(img_path, df, preprocess=False), cmap='gray')\n",
        "            plt.imshow(gradcam, cmap='jet', alpha=min(0.5, predictions[0][i]))\n",
        "            j +=1\n",
        "\n",
        "\n",
        "def cindex(y_true, scores):\n",
        "    return lifelines.utils.concordance_index(y_true, scores)\n",
        "\n",
        "# LOAD MODEL FROM C1M2\n",
        "def load_C3M3_model():\n",
        "    labels = ['Cardiomegaly', 'Emphysema', 'Effusion', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Atelectasis',\n",
        "              'Pneumothorax', 'Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema', 'Consolidation']\n",
        "\n",
        "    train_df = pd.read_csv(\"train-small.csv\")\n",
        "    valid_df = pd.read_csv(\"valid-small.csv\")\n",
        "    test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "    class_pos = train_df.loc[:, labels].sum(axis=0)\n",
        "    class_neg = len(train_df) - class_pos\n",
        "    class_total = class_pos + class_neg\n",
        "\n",
        "    pos_weights = class_pos / class_total\n",
        "    neg_weights = class_neg / class_total\n",
        "    print(\"Got loss weights\")\n",
        "    # create the base pre-trained model\n",
        "    base_model = DenseNet121(weights='densenet.hdf5', include_top=False)\n",
        "    print(\"Loaded DenseNet\")\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # and a logistic layer\n",
        "    predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n",
        "    print(\"Added layers\")\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    def get_weighted_loss(neg_weights, pos_weights, epsilon=1e-7):\n",
        "        def weighted_loss(y_true, y_pred):\n",
        "            # L(X, y) = −w * y log p(Y = 1|X) − w *  (1 − y) log p(Y = 0|X)\n",
        "            # from https://arxiv.org/pdf/1711.05225.pdf\n",
        "            loss = 0\n",
        "            for i in range(len(neg_weights)):\n",
        "                loss -= (neg_weights[i] * y_true[:, i] * K.log(y_pred[:, i] + epsilon) + \n",
        "                         pos_weights[i] * (1 - y_true[:, i]) * K.log(1 - y_pred[:, i] + epsilon))\n",
        "            \n",
        "            loss = K.sum(loss)\n",
        "            return loss\n",
        "        return weighted_loss\n",
        "    \n",
        "    model.compile(optimizer='adam', loss=get_weighted_loss(neg_weights, pos_weights))\n",
        "    print(\"Compiled Model\")\n",
        "\n",
        "    model.load_weights(\"pretrained_model.h5\")\n",
        "    print(\"Loaded Weights\")\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaU2p6bQ8RLl",
        "colab_type": "text"
      },
      "source": [
        "The `load_C3M3_model()` function has been taken care of and as last time, its internals are out of the scope of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ozAKgd8RLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the model we used last time\n",
        "model = load_C3M3_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMByIcry8RLo",
        "colab_type": "text"
      },
      "source": [
        "Kindly recall from the previous notebook (GradCAM Part 1) that our model has 428 layers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxHm0Tq48RLp",
        "colab_type": "text"
      },
      "source": [
        "We are now interested in getting the gradients when the model outputs a specific class. For this we will use Keras backend's `gradients(..)` function. This function requires two arguments: \n",
        "\n",
        "  - Loss (scalar tensor)\n",
        "  - List of variables\n",
        "  \n",
        "Since we want the gradients with respect to the output, we can use our model's output tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAMfocrl8RLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model's output in a variable\n",
        "y = model.output\n",
        "\n",
        "# Print model's output\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WokcjP-z8RLs",
        "colab_type": "text"
      },
      "source": [
        "However this is not a scalar (aka rank-0) tensor because it has axes. To transform this tensor into a scalar we can slice it like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5PDqVem8RLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y[0]\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd0vgUWx8RLw",
        "colab_type": "text"
      },
      "source": [
        "It is still *not* a scalar tensor so we will have to slice it again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svsqCYxD8RLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y[0]\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ3uUOp98RLz",
        "colab_type": "text"
      },
      "source": [
        "Now it is a scalar tensor!\n",
        "\n",
        "The above slicing could be done in a single statement like this:\n",
        "\n",
        "```python\n",
        "y = y[0,0]\n",
        "```\n",
        "\n",
        "But the explicit version of it was shown for visibility purposes.\n",
        "\n",
        "The first argument required by `gradients(..)` function is the loss, which we will like to get the gradient of, and the second is a list of parameters to compute the gradient with respect to. Since we are interested in getting the gradient of the output of the model with respect to the output of the last convolutional layer we need to specify the layer as we did  in the previous notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY5MffUG8RLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the desired layer in a variable\n",
        "layer = model.get_layer(\"conv5_block16_concat\")\n",
        "\n",
        "# Compute gradient of model's output with respect to last conv layer's output\n",
        "gradients = K.gradients(y, layer.output)\n",
        "\n",
        "# Print gradients list\n",
        "gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F04r2NtI8RL2",
        "colab_type": "text"
      },
      "source": [
        "Notice that the gradients function returns a list of placeholder tensors. To get the actual placeholder we will get the first element of this list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-AoVwAS8RL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get first (and only) element in the list\n",
        "gradients = gradients[0]\n",
        "\n",
        "# Print tensor placeholder\n",
        "gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD1QksMR8RL5",
        "colab_type": "text"
      },
      "source": [
        "As with the activations of the last convolutional layer in the previous notebook, we still need a function that uses this placeholder to compute the actual values for an input image. This can be done in the same manner as before. Remember this **function expects its arguments as lists or tuples**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAmIqMVC8RL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the function to compute the gradients\n",
        "gradients_function = K.function([model.input], [gradients])\n",
        "\n",
        "# Print the gradients function\n",
        "gradients_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPQtdXpz8RL7",
        "colab_type": "text"
      },
      "source": [
        "Now that we have the function for computing the gradients, let's test it out on a particular image. Don't worry about the code to load the image, this has been taken care of for you, you should only care that an image ready to be processed will be saved in the x variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypc4Y6cV8RL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dataframe that contains information about the dataset of images\n",
        "df = pd.read_csv(\"train-small.csv\")\n",
        "\n",
        "# Path to the actual image\n",
        "im_path = 'small_data/00000599_000.png'\n",
        "\n",
        "# Load the image and save it to a variable\n",
        "x = load_image(im_path, df, preprocess=False)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(x, cmap = 'gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqbgrUoj8RL_",
        "colab_type": "text"
      },
      "source": [
        "We should normalize this image before going forward, this has also been taken care of:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEdkFt0H8RMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate mean and standard deviation of a batch of images\n",
        "mean, std = get_mean_std_per_batch(df)\n",
        "\n",
        "# Normalize image\n",
        "x = load_image_normalize(im_path, mean, std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj1ffXw_8RMC",
        "colab_type": "text"
      },
      "source": [
        "Now we have everything we need to compute the actual values of the gradients. In this case we should also **provide the input as a list or tuple**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2RE1eHA8RMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the function on the image and save it in a variable\n",
        "actual_gradients = gradients_function([x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KklDdbd8RMF",
        "colab_type": "text"
      },
      "source": [
        "An important intermediary step is to trim the batch dimension which can be done like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZAoakid8RMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove batch dimension\n",
        "actual_gradients = actual_gradients[0][0, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMjE1_oz8RMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print shape of the gradients array\n",
        "print(f\"Gradients of model's output with respect to output of last convolutional layer have shape: {actual_gradients.shape}\")\n",
        "\n",
        "# Print gradients array\n",
        "actual_gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cg0eP6U8RMK",
        "colab_type": "text"
      },
      "source": [
        "Looks like everything worked out nicely! You will still have to wait for the assignment to see how these elements are used by Grad-CAM to get visual interpretations. Before you go you should know that there is a shortcut for these calculations by getting both elements from a single Keras function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvEWwyrr8RMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save multi-input Keras function in a variable\n",
        "activations_and_gradients_function = K.function([model.input], [layer.output, gradients])\n",
        "\n",
        "# Run the function on our image\n",
        "act_x, grad_x = activations_and_gradients_function([x])\n",
        "\n",
        "# Remove batch dimension for both arrays\n",
        "act_x = act_x[0, :]\n",
        "grad_x = grad_x[0, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqWkdB1F8RMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print actual activations\n",
        "print(act_x)\n",
        "\n",
        "# Print actual gradients\n",
        "print(grad_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZv_r9OP8RMP",
        "colab_type": "text"
      },
      "source": [
        "**Congratulations on finishing this lecture notebook!** Hopefully you will now have a better understanding of how to leverage Keras's API power for computing gradients. Keep it up!"
      ]
    }
  ]
}